{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3850faf6",
   "metadata": {},
   "source": [
    "# Preprocess Soil CSVs\n",
    "This notebook preprocesses per-state/year CSV files stored under `Soil_data/2018` and `Soil_data/2020`.\n",
    "Run the next code cell to: import libraries, resolve the notebook `root` folder (uses `ipynbname` when available), and define helper functions that add `Year`, `Month`, and `Day` columns to each CSV.\n",
    "Notes: the date parser uses `pandas.to_datetime(..., errors='coerce', dayfirst=True)` and will coerce unparseable dates to `NaT`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2271828",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "# Ignore pandas UserWarning messages (broader match so suppression works reliably)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Resolve the notebook directory (use ipynbname if available, otherwise fallback to cwd)\n",
    "try:\n",
    "    import ipynbname\n",
    "    root = Path(ipynbname.path()).parent\n",
    "except Exception:\n",
    "    root = Path.cwd()\n",
    "\n",
    "# Folder containing all your CSV files (relative to this notebook's location)\n",
    "base_folder_2020 = root / 'Soil_data' / '2020'\n",
    "base_folder_2018 = root / 'Soil_data' / '2018'\n",
    "\n",
    "def process_csv(csv_path):\n",
    "    print(f\"\\nâž¡ Processing: {csv_path}\")\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Standardize column names\n",
    "    df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
    "\n",
    "    # If all columns exist -> skip file\n",
    "    if all(col in df.columns for col in [\"year\", \"month\", \"day\"]):\n",
    "        print(\"âœ” Already has Year/Month/Day â†’ Skipping\")\n",
    "        return\n",
    "\n",
    "    # Detect date column\n",
    "    date_cols = [c for c in df.columns if \"date\" in c]\n",
    "    if not date_cols:\n",
    "        print(\"âŒ No date column found â†’ skipping\")\n",
    "        return\n",
    "\n",
    "    date_col = date_cols[0]\n",
    "    print(f\"   Using date column: {date_col}\")\n",
    "\n",
    "    # Parse date safely â€” removed deprecated infer_datetime_format to avoid warning\n",
    "    df[\"date_parsed\"] = pd.to_datetime(\n",
    "        df[date_col],\n",
    "        errors=\"coerce\",\n",
    "        dayfirst=True\n",
    "    )\n",
    "\n",
    "    # Create new columns\n",
    "    df[\"Year\"] = df[\"date_parsed\"].dt.year\n",
    "    df[\"Month\"] = df[\"date_parsed\"].dt.strftime(\"%b\")  # Jan, Feb, Mar\n",
    "    df[\"Day\"] = df[\"date_parsed\"].dt.day\n",
    "\n",
    "    # Drop helper column\n",
    "    df.drop(columns=[\"date_parsed\"], inplace=True)\n",
    "\n",
    "    # Save back to SAME file\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(\"âœ” Updated Year / Month / Day added.\")\n",
    "\n",
    "\n",
    "def scan_and_process_all(folder):\n",
    "    print(\"\\nðŸ” Scanning for CSV files...\\n\")\n",
    "    \n",
    "    for root_dir, dirs, files in os.walk(folder):\n",
    "        for file in files:\n",
    "            if file.endswith(\".csv\"):\n",
    "                csv_path = os.path.join(root_dir, file)\n",
    "                process_csv(csv_path)\n",
    "\n",
    "    print(\"\\nðŸŽ‰ ALL FILES PROCESSED SUCCESSFULLY!\")\n",
    "\n",
    "# Run the scanner\n",
    "scan_and_process_all(base_folder_2018)\n",
    "scan_and_process_all(base_folder_2020)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee717e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge per-year CSVs into single files\n",
    "# This cell defines `merge_csv_if_not_exists` and runs it for 2018 and 2020.\n",
    "# If an output file already exists, the function will skip merging to avoid overwriting.\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# -------------------------------------------\n",
    "# Function to merge all CSVs inside a folder\n",
    "# -------------------------------------------\n",
    "def merge_csv_if_not_exists(base_folder, output_file):\n",
    "    base_folder = Path(base_folder)\n",
    "\n",
    "    # If merged file already exists â†’ skip merging\n",
    "    if os.path.exists(output_file):\n",
    "        print(f\"âœ” {output_file} already exists â€“ skipping merging.\")\n",
    "        return\n",
    "\n",
    "    print(f\"â³ Merging CSV files from: {base_folder}\")\n",
    "\n",
    "    # Collect all CSV files\n",
    "    all_files = []\n",
    "    for root_dir, dirs, files in os.walk(base_folder):\n",
    "        for file in files:\n",
    "            if file.endswith(\".csv\"):\n",
    "                csv_path = os.path.join(root_dir, file)\n",
    "                all_files.append(csv_path)\n",
    "\n",
    "    # Safety check\n",
    "    if not all_files:\n",
    "        print(f\"âŒ No CSV files found in {base_folder}\")\n",
    "        return\n",
    "\n",
    "    # Merge all CSVs\n",
    "    df_list = [pd.read_csv(file) for file in all_files]\n",
    "    df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "    # Save merged file\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"âœ” Merged and saved: {output_file}\")\n",
    "\n",
    "\n",
    "# -------------------------------------------\n",
    "# Merge 2018 (Only if file doesn't exist)\n",
    "# -------------------------------------------\n",
    "merge_csv_if_not_exists(\n",
    "    base_folder=\"Soil_data/2018\",\n",
    "    output_file=\"merged_soil_data_2018.csv\"\n",
    ")\n",
    "\n",
    "# -------------------------------------------\n",
    "# Merge 2020 (Only if file doesn't exist)\n",
    "# -------------------------------------------\n",
    "merge_csv_if_not_exists(\n",
    "    base_folder=\"Soil_data/2020\",\n",
    "    output_file=\"merged_soil_data_2020.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43941599",
   "metadata": {},
   "source": [
    "# Cleaning merged files\n",
    "The next cell loads the merged per-year CSVs, reports shape and NaN counts, and (by default) drops any row that contains a NaN value.\n",
    "Warning: this cleaning is aggressive â€” it overwrites the input files. Adjust the code if you prefer a less destructive approach (for example, drop only rows missing critical columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c4562f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def clean_csv(csv_path):\n",
    "\n",
    "    print(f\"\\n==============================\")\n",
    "    print(f\"Cleaning File: {csv_path}\")\n",
    "    print(f\"==============================\")\n",
    "\n",
    "    # Load CSV\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Shape & NaN count\n",
    "    print(\"Shape:\", df.shape)\n",
    "    print(\"\\nNaN count per column:\")\n",
    "    print(df.isna().sum())\n",
    "\n",
    "    # Drop rows with ANY NaN\n",
    "    df_cleaned = df.dropna(how=\"any\")\n",
    "\n",
    "    # Save (overwrite)\n",
    "    df_cleaned.to_csv(csv_path, index=False)\n",
    "\n",
    "    print(f\"\\nâœ” Cleaned CSV saved: {csv_path}\")\n",
    "    print(f\"âœ” Final shape: {df_cleaned.shape}\")\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Clean Both Files\n",
    "# ----------------------------\n",
    "\n",
    "clean_csv(\"merged_soil_data_2018.csv\")\n",
    "clean_csv(\"merged_soil_data_2020.csv\")\n",
    "\n",
    "print(\"\\nðŸŽ‰ All files cleaned successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6032150f",
   "metadata": {},
   "source": [
    "# Create final combined file\n",
    "This cell concatenates the cleaned 2018 and 2020 CSVs into a single `merged_final.csv`. It prints a few duplicate rows before removing duplicates and can optionally drop rows with any NaN values.\n",
    "Review the printed shapes and duplicate samples before changing cleaning flags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a8fcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Merge two soil CSVs into a single merged_final.csv\n",
    "\n",
    "Added:\n",
    "- Print first 5 duplicate rows before dropping duplicates\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# -------- CONFIG --------\n",
    "# Resolve the notebook directory (use ipynbname if available, otherwise fallback to cwd)\n",
    "try:\n",
    "    import ipynbname\n",
    "    root = Path(ipynbname.path()).parent\n",
    "except Exception:\n",
    "    root = Path.cwd()\n",
    "\n",
    "file_2018 = root / \"merged_soil_data_2018.csv\"\n",
    "file_2020 = root / \"merged_soil_data_2020.csv\"\n",
    "out_file = root / \"merged_final.csv\"\n",
    "\n",
    "drop_any_nan = True       # set True to drop rows that contain any NaN\n",
    "drop_duplicates = True     # set True to remove exact duplicate rows\n",
    "\n",
    "# -------- helper --------\n",
    "def read_csv_fallback(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Try utf-8 then latin1; set low_memory False and skip bad lines.\"\"\"\n",
    "    try:\n",
    "        return pd.read_csv(path, encoding=\"utf-8\", low_memory=False, on_bad_lines=\"skip\")\n",
    "    except Exception:\n",
    "        return pd.read_csv(path, encoding=\"latin1\", low_memory=False, on_bad_lines=\"skip\")\n",
    "\n",
    "# -------- read --------\n",
    "print(\"Reading files...\")\n",
    "df18 = read_csv_fallback(file_2018)\n",
    "print(f\"  {file_2018.name}: shape {df18.shape}\")\n",
    "\n",
    "df20 = read_csv_fallback(file_2020)\n",
    "print(f\"  {file_2020.name}: shape {df20.shape}\")\n",
    "\n",
    "# -------- merge --------\n",
    "print(\"Concatenating...\")\n",
    "merged = pd.concat([df18, df20], ignore_index=True, sort=False)\n",
    "print(\"  merged shape (before cleaning):\", merged.shape)\n",
    "\n",
    "# -------- show 5 duplicates BEFORE cleaning --------\n",
    "duplicate_rows = merged[merged.duplicated(keep=False)]\n",
    "\n",
    "print(\"\\n--- First 5 Duplicate Rows (Before Removing Duplicates) ---\")\n",
    "if duplicate_rows.empty:\n",
    "    print(\"No duplicates found.\")\n",
    "else:\n",
    "    print(duplicate_rows.head(5))\n",
    "\n",
    "# -------- optional cleaning --------\n",
    "if drop_any_nan:\n",
    "    before = len(merged)\n",
    "    merged = merged.dropna(how=\"any\")\n",
    "    print(f\"  dropped {before - len(merged)} rows with any NaN -> shape {merged.shape}\")\n",
    "\n",
    "if drop_duplicates:\n",
    "    before = len(merged)\n",
    "    merged = merged.drop_duplicates().reset_index(drop=True)\n",
    "    print(f\"  dropped {before - len(merged)} duplicate rows -> shape {merged.shape}\")\n",
    "\n",
    "# -------- save --------\n",
    "merged.to_csv(out_file, index=False)\n",
    "print(f\"\\nâœ” Merged CSV saved to: {out_file}\")\n",
    "print(\"Final shape:\", merged.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087363f3",
   "metadata": {},
   "source": [
    "# State â†’ Season mapping\n",
    "The following cell defines `state_season_map`, a dictionary mapping state names to lists of month abbreviations for each season. This is used to derive a `Season` column for each row in the final merged CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5311881a",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_season_map = {\n",
    "\n",
    "    # ====== SOUTH INDIA ======\n",
    "    \"ANDHRA PRADESH\": {\n",
    "        \"Winter\": [\"DEC\", \"JAN\", \"FEB\"],\n",
    "        \"Summer\": [\"MAR\", \"APR\", \"MAY\"],\n",
    "        \"Monsoon\": [\"JUN\", \"JUL\", \"AUG\", \"SEP\"],\n",
    "        \"Post-monsoon\": [\"OCT\", \"NOV\"]\n",
    "    },\n",
    "    \"TELANGANA\": {\n",
    "        \"Winter\": [\"DEC\", \"JAN\", \"FEB\"],\n",
    "        \"Summer\": [\"MAR\", \"APR\", \"MAY\"],\n",
    "        \"Monsoon\": [\"JUN\", \"JUL\", \"AUG\", \"SEP\"],\n",
    "        \"Post-monsoon\": [\"OCT\", \"NOV\"]\n",
    "    },\n",
    "    \"TAMILNADU\": {\n",
    "        \"Winter\": [\"JAN\", \"FEB\"],\n",
    "        \"Summer\": [\"MAR\", \"APR\", \"MAY\"],\n",
    "        \"Monsoon\": [\"JUN\", \"JUL\", \"AUG\", \"SEP\"],\n",
    "        \"Post-monsoon\": [\"OCT\", \"NOV\", \"DEC\"]\n",
    "    },\n",
    "    \"KARNATAKA\": {\n",
    "        \"Winter\": [\"JAN\", \"FEB\"],\n",
    "        \"Summer\": [\"MAR\", \"APR\", \"MAY\"],\n",
    "        \"Monsoon\": [\"JUN\", \"JUL\", \"AUG\", \"SEP\"],\n",
    "        \"Post-monsoon\": [\"OCT\", \"NOV\", \"DEC\"]\n",
    "    },\n",
    "    \"KERALA\": {\n",
    "        \"Winter\": [\"DEC\", \"JAN\", \"FEB\"],\n",
    "        \"Summer\": [\"MAR\", \"APR\", \"MAY\"],\n",
    "        \"Monsoon\": [\"JUN\", \"JUL\", \"AUG\", \"SEP\"],\n",
    "        \"Post-monsoon\": [\"OCT\", \"NOV\"]\n",
    "    },\n",
    "    \"LAKSHDWEEP\": {\n",
    "        \"Winter\": [\"DEC\", \"JAN\", \"FEB\"],\n",
    "        \"Summer\": [\"MAR\", \"APR\"],\n",
    "        \"Monsoon\": [\"MAY\", \"JUN\", \"JUL\", \"AUG\", \"SEP\"],\n",
    "        \"Post-monsoon\": [\"OCT\", \"NOV\"]\n",
    "    },\n",
    "    \"PONDICHERRY\": {\n",
    "        \"Winter\": [\"JAN\", \"FEB\"],\n",
    "        \"Summer\": [\"MAR\", \"APR\", \"MAY\"],\n",
    "        \"Monsoon\": [\"JUN\", \"JUL\", \"AUG\", \"SEP\"],\n",
    "        \"Post-monsoon\": [\"OCT\", \"NOV\", \"DEC\"]\n",
    "    },\n",
    "\n",
    "    # ====== NORTH INDIA ======\n",
    "    \"DELHI\": {\n",
    "        \"Winter\": [\"DEC\", \"JAN\", \"FEB\"],\n",
    "        \"Summer\": [\"MAR\", \"APR\", \"MAY\"],\n",
    "        \"Monsoon\": [\"JUN\", \"JUL\", \"AUG\", \"SEP\"],\n",
    "        \"Post-monsoon\": [\"OCT\", \"NOV\"]\n",
    "    },\n",
    "    \"PUNJAB\": {\n",
    "        \"Winter\": [\"DEC\", \"JAN\", \"FEB\"],\n",
    "        \"Summer\": [\"MAR\", \"APR\", \"MAY\"],\n",
    "        \"Monsoon\": [\"JUN\", \"JUL\", \"AUG\", \"SEP\"],\n",
    "        \"Post-monsoon\": [\"OCT\", \"NOV\"]\n",
    "    },\n",
    "    \"HARYANA\": {\n",
    "        \"Winter\": [\"DEC\", \"JAN\", \"FEB\"],\n",
    "        \"Summer\": [\"MAR\", \"APR\", \"MAY\"],\n",
    "        \"Monsoon\": [\"JUN\", \"JUL\", \"AUG\", \"SEP\"],\n",
    "        \"Post-monsoon\": [\"OCT\", \"NOV\"]\n",
    "    },\n",
    "    \"HIMACHAL PRADESH\": {\n",
    "        \"Winter\": [\"NOV\", \"DEC\", \"JAN\", \"FEB\"],\n",
    "        \"Summer\": [\"MAR\", \"APR\", \"MAY\"],\n",
    "        \"Monsoon\": [\"JUN\", \"JUL\", \"AUG\", \"SEP\"],\n",
    "        \"Post-monsoon\": [\"OCT\"]\n",
    "    },\n",
    "    \"UTTARAKHAND\": {\n",
    "        \"Winter\": [\"DEC\", \"JAN\", \"FEB\"],\n",
    "        \"Summer\": [\"MAR\", \"APR\", \"MAY\"],\n",
    "        \"Monsoon\": [\"JUN\", \"JUL\", \"AUG\", \"SEP\"],\n",
    "        \"Post-monsoon\": [\"OCT\", \"NOV\"]\n",
    "    },\n",
    "    \"UTTAR PRADESH\": {\n",
    "        \"Winter\": [\"DEC\", \"JAN\", \"FEB\"],\n",
    "        \"Summer\": [\"MAR\", \"APR\", \"MAY\"],\n",
    "        \"Monsoon\": [\"JUN\", \"JUL\", \"AUG\", \"SEP\"],\n",
    "        \"Post-monsoon\": [\"OCT\", \"NOV\"]\n",
    "    },\n",
    "    \"JAMMU & KASHMIR\": {\n",
    "        \"Winter\": [\"NOV\", \"DEC\", \"JAN\", \"FEB\"],\n",
    "        \"Summer\": [\"MAR\", \"APR\", \"MAY\"],\n",
    "        \"Monsoon\": [\"JUN\", \"JUL\", \"AUG\", \"SEP\"],\n",
    "        \"Post-monsoon\": [\"OCT\"]\n",
    "    },\n",
    "    \"LADAKH\": {\n",
    "        \"Winter\": [\"OCT\", \"NOV\", \"DEC\", \"JAN\", \"FEB\"],\n",
    "        \"Summer\": [\"MAR\", \"APR\", \"MAY\"],\n",
    "        \"Monsoon\": [\"JUN\", \"JUL\", \"AUG\"],\n",
    "        \"Post-monsoon\": [\"SEP\"]\n",
    "    },\n",
    "    \"CHANDIGARH\": {\n",
    "        \"Winter\": [\"DEC\", \"JAN\", \"FEB\"],\n",
    "        \"Summer\": [\"MAR\", \"APR\", \"MAY\"],\n",
    "        \"Monsoon\": [\"JUN\", \"JUL\", \"AUG\", \"SEP\"],\n",
    "        \"Post-monsoon\": [\"OCT\", \"NOV\"]\n",
    "    },\n",
    "\n",
    "    # ====== EAST INDIA ======\n",
    "    \"WEST BENGAL\": {\n",
    "        \"Winter\": [\"DEC\", \"JAN\", \"FEB\"],\n",
    "        \"Summer\": [\"MAR\", \"APR\", \"MAY\"],\n",
    "        \"Monsoon\": [\"JUN\", \"JUL\", \"AUG\", \"SEP\"],\n",
    "        \"Post-monsoon\": [\"OCT\", \"NOV\"]\n",
    "    },\n",
    "    \"BIHAR\": {\n",
    "        \"Winter\": [\"DEC\", \"JAN\", \"FEB\"],\n",
    "        \"Summer\": [\"MAR\", \"APR\"],\n",
    "        \"Monsoon\": [\"MAY\", \"JUN\", \"JUL\", \"AUG\", \"SEP\"],\n",
    "        \"Post-monsoon\": [\"OCT\", \"NOV\"]\n",
    "    },\n",
    "    \"JHARKHAND\": {\n",
    "        \"Winter\": [\"DEC\", \"JAN\", \"FEB\"],\n",
    "        \"Summer\": [\"MAR\", \"APR\", \"MAY\"],\n",
    "        \"Monsoon\": [\"JUN\", \"JUL\", \"AUG\", \"SEP\"],\n",
    "        \"Post-monsoon\": [\"OCT\", \"NOV\"]\n",
    "    },\n",
    "    \"ODISHA\": {\n",
    "        \"Winter\": [\"DEC\", \"JAN\", \"FEB\"],\n",
    "        \"Summer\": [\"MAR\", \"APR\", \"MAY\"],\n",
    "        \"Monsoon\": [\"JUN\", \"JUL\", \"AUG\", \"SEP\"],\n",
    "        \"Post-monsoon\": [\"OCT\", \"NOV\"]\n",
    "    },\n",
    "\n",
    "    # ====== WEST INDIA ======\n",
    "    \"GUJARAT\": {\n",
    "        \"Winter\": [\"DEC\", \"JAN\", \"FEB\"],\n",
    "        \"Summer\": [\"MAR\", \"APR\", \"MAY\"],\n",
    "        \"Monsoon\": [\"JUN\", \"JUL\", \"AUG\", \"SEP\"],\n",
    "        \"Post-monsoon\": [\"OCT\", \"NOV\"]\n",
    "    },\n",
    "    \"RAJASTHAN\": {\n",
    "        \"Winter\": [\"DEC\", \"JAN\", \"FEB\"],\n",
    "        \"Summer\": [\"MAR\", \"APR\", \"MAY\"],\n",
    "        \"Monsoon\": [\"JUN\", \"JUL\", \"AUG\", \"SEP\"],\n",
    "        \"Post-monsoon\": [\"OCT\", \"NOV\"]\n",
    "    },\n",
    "    \"MAHARASHTRA\": {\n",
    "        \"Winter\": [\"DEC\", \"JAN\", \"FEB\"],\n",
    "        \"Summer\": [\"MAR\", \"APR\", \"MAY\"],\n",
    "        \"Monsoon\": [\"JUN\", \"JUL\", \"AUG\", \"SEP\"],\n",
    "        \"Post-monsoon\": [\"OCT\", \"NOV\"]\n",
    "    },\n",
    "    \"GOA\": {\n",
    "        \"Winter\": [\"DEC\", \"JAN\"],\n",
    "        \"Summer\": [\"FEB\", \"MAR\", \"APR\"],\n",
    "        \"Monsoon\": [\"MAY\", \"JUN\", \"JUL\", \"AUG\", \"SEP\"],\n",
    "        \"Post-monsoon\": [\"OCT\", \"NOV\"]\n",
    "    },\n",
    "    \"DADRA AND NAGAR HAV\": {\n",
    "        \"Winter\": [\"DEC\", \"JAN\"],\n",
    "        \"Summer\": [\"FEB\", \"MAR\", \"APR\"],\n",
    "        \"Monsoon\": [\"MAY\", \"JUN\", \"JUL\", \"AUG\", \"SEP\"],\n",
    "        \"Post-monsoon\": [\"OCT\", \"NOV\"]\n",
    "    },\n",
    "    \"DAMAN & DIU\": {\n",
    "        \"Winter\": [\"DEC\", \"JAN\"],\n",
    "        \"Summer\": [\"FEB\", \"MAR\", \"APR\"],\n",
    "        \"Monsoon\": [\"MAY\", \"JUN\", \"JUL\", \"AUG\", \"SEP\"],\n",
    "        \"Post-monsoon\": [\"OCT\", \"NOV\"]\n",
    "    },\n",
    "\n",
    "    # ====== CENTRAL INDIA ======\n",
    "    \"MADHYA PRADESH\": {\n",
    "        \"Winter\": [\"DEC\", \"JAN\", \"FEB\"],\n",
    "        \"Summer\": [\"MAR\", \"APR\", \"MAY\"],\n",
    "        \"Monsoon\": [\"JUN\", \"JUL\", \"AUG\", \"SEP\"],\n",
    "        \"Post-monsoon\": [\"OCT\", \"NOV\"]\n",
    "    },\n",
    "    \"CHHATTISGARH\": {\n",
    "        \"Winter\": [\"DEC\", \"JAN\", \"FEB\"],\n",
    "        \"Summer\": [\"MAR\", \"APR\", \"MAY\"],\n",
    "        \"Monsoon\": [\"JUN\", \"JUL\", \"AUG\", \"SEP\"],\n",
    "        \"Post-monsoon\": [\"OCT\", \"NOV\"]\n",
    "    },\n",
    "\n",
    "    # ====== NORTHEAST INDIA ======\n",
    "    \"ASSAM\": {\n",
    "        \"Winter\": [\"DEC\", \"JAN\", \"FEB\"],\n",
    "        \"Summer\": [\"MAR\", \"APR\"],\n",
    "        \"Monsoon\": [\"MAY\", \"JUN\", \"JUL\", \"AUG\", \"SEP\", \"OCT\"],\n",
    "        \"Post-monsoon\": [\"NOV\"]\n",
    "    },\n",
    "    \"ARUNACHAL PRADESH\": {\n",
    "        \"Winter\": [\"DEC\", \"JAN\", \"FEB\"],\n",
    "        \"Summer\": [\"MAR\", \"APR\"],\n",
    "        \"Monsoon\": [\"MAY\", \"JUN\", \"JUL\", \"AUG\", \"SEP\"],\n",
    "        \"Post-monsoon\": [\"OCT\", \"NOV\"]\n",
    "    },\n",
    "    \"MANIPUR\": {\n",
    "        \"Winter\": [\"DEC\", \"JAN\", \"FEB\"],\n",
    "        \"Summer\": [\"MAR\", \"APR\"],\n",
    "        \"Monsoon\": [\"MAY\", \"JUN\", \"JUL\", \"AUG\", \"SEP\", \"OCT\"],\n",
    "        \"Post-monsoon\": [\"NOV\"]\n",
    "    },\n",
    "    \"MEGHALAYA\": {\n",
    "        \"Winter\": [\"DEC\", \"JAN\", \"FEB\"],\n",
    "        \"Summer\": [\"MAR\", \"APR\"],\n",
    "        \"Monsoon\": [\"MAY\", \"JUN\", \"JUL\", \"AUG\", \"SEP\", \"OCT\"],\n",
    "        \"Post-monsoon\": [\"NOV\"]\n",
    "    },\n",
    "    \"MIZORAM\": {\n",
    "        \"Winter\": [\"DEC\", \"JAN\", \"FEB\"],\n",
    "        \"Summer\": [\"MAR\", \"APR\"],\n",
    "        \"Monsoon\": [\"MAY\", \"JUN\", \"JUL\", \"AUG\", \"SEP\", \"OCT\"],\n",
    "        \"Post-monsoon\": [\"NOV\"]\n",
    "    },\n",
    "    \"NAGALAND\": {\n",
    "        \"Winter\": [\"DEC\", \"JAN\", \"FEB\"],\n",
    "        \"Summer\": [\"MAR\", \"APR\"],\n",
    "        \"Monsoon\": [\"MAY\", \"JUN\", \"JUL\", \"AUG\", \"SEP\", \"OCT\"],\n",
    "        \"Post-monsoon\": [\"NOV\"]\n",
    "    },\n",
    "    \"SIKKIM\": {\n",
    "        \"Winter\": [\"DEC\", \"JAN\", \"FEB\"],\n",
    "        \"Summer\": [\"MAR\", \"APR\"],\n",
    "        \"Monsoon\": [\"MAY\", \"JUN\", \"JUL\", \"AUG\", \"SEP\"],\n",
    "        \"Post-monsoon\": [\"OCT\", \"NOV\"]\n",
    "    },\n",
    "    \"TRIPURA\": {\n",
    "        \"Winter\": [\"DEC\", \"JAN\", \"FEB\"],\n",
    "        \"Summer\": [\"MAR\", \"APR\"],\n",
    "        \"Monsoon\": [\"MAY\", \"JUN\", \"JUL\", \"AUG\", \"SEP\", \"OCT\"],\n",
    "        \"Post-monsoon\": [\"NOV\"]\n",
    "    },\n",
    "\n",
    "    # ====== ISLANDS ======\n",
    "    \"ANDAMAN & NICOBAR\": {\n",
    "        \"Winter\": [\"DEC\", \"JAN\", \"FEB\"],\n",
    "        \"Summer\": [\"MAR\", \"APR\"],\n",
    "        \"Monsoon\": [\"MAY\", \"JUN\", \"JUL\", \"AUG\", \"SEP\", \"OCT\"],\n",
    "        \"Post-monsoon\": [\"NOV\"]\n",
    "    },\n",
    "\n",
    "    None: {\n",
    "        \"Winter\": [],\n",
    "        \"Summer\": [],\n",
    "        \"Monsoon\": [],\n",
    "        \"Post-monsoon\": []\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1b0e38",
   "metadata": {},
   "source": [
    "# Apply season mapping and write results\n",
    "This cell defines `get_season`, detects the state and month columns in `merged_final.csv`, normalizes month values, computes the `Season` column, prints a summary of unknown mappings, and overwrites the final CSV with the new `Season` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814f79b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------\n",
    "# get_season function (your original, unchanged)\n",
    "# ---------------------\n",
    "def get_season(state, month):\n",
    "    \"\"\"\n",
    "    Returns the season (Winter, Summer, Monsoon, Post-monsoon) \n",
    "    based on state and month abbreviation.\n",
    "    \"\"\"\n",
    "    if pd.isna(state) or pd.isna(month):\n",
    "        return \"Unknown\"\n",
    "\n",
    "    state = state.upper().strip()\n",
    "    month = month.upper().strip()\n",
    "\n",
    "    if state not in state_season_map:\n",
    "        return \"Unknown\"\n",
    "\n",
    "    season_info = state_season_map[state]\n",
    "\n",
    "    for season_name, month_list in season_info.items():\n",
    "        if month in month_list:\n",
    "            return season_name\n",
    "\n",
    "    return \"Unknown\"\n",
    "\n",
    "# ---------------------\n",
    "# Read final merged CSV\n",
    "# ---------------------\n",
    "df = pd.read_csv(out_file, low_memory=False)\n",
    "print(f\"Loaded {out_file} -> shape {df.shape}\")\n",
    "\n",
    "# ---------------------\n",
    "# Detect state column robustly\n",
    "# ---------------------\n",
    "col_map = {c.lower().strip(): c for c in df.columns}\n",
    "state_candidates = [\"state_name\", \"state name\", \"state\"]\n",
    "state_col = None\n",
    "for cand in state_candidates:\n",
    "    if cand in col_map:\n",
    "        state_col = col_map[cand]\n",
    "        break\n",
    "if state_col is None:\n",
    "    raise KeyError(f\"State column not found. Available columns: {list(df.columns)}\")\n",
    "\n",
    "# ---------------------\n",
    "# Normalize Month column and apply Season mapping\n",
    "# ---------------------\n",
    "# Ensure Month column exists; common names: 'Month', 'month'\n",
    "month_col = None\n",
    "for cand in [\"month\", \"Month\"]:\n",
    "    if cand in df.columns:\n",
    "        month_col = cand\n",
    "        break\n",
    "if month_col is None:\n",
    "    # create Month col if missing\n",
    "    df[\"Month\"] = pd.NA\n",
    "    month_col = \"Month\"\n",
    "\n",
    "# Normalize Month values (strip, uppercase). Keep empty as NA\n",
    "df[month_col] = df[month_col].astype(str).str.strip().replace({\"\": pd.NA, \"nan\": pd.NA})\n",
    "df[month_col] = df[month_col].where(df[month_col].notna(), pd.NA)\n",
    "df[month_col] = df[month_col].astype(str).str.upper().str.strip().replace({\"NAN\": pd.NA})\n",
    "df[month_col] = df[month_col].where(df[month_col].notna(), pd.NA)\n",
    "\n",
    "# Apply Season using the detected state column\n",
    "df[\"Season\"] = df.apply(lambda row: get_season(row[state_col], row[month_col]), axis=1)\n",
    "\n",
    "# ---------------------\n",
    "# Summary & sample of Unknown\n",
    "# ---------------------\n",
    "print(\"\\nSeason value counts:\")\n",
    "print(df[\"Season\"].value_counts(dropna=False))\n",
    "\n",
    "unknown_count = (df[\"Season\"] == \"Unknown\").sum()\n",
    "print(f\"\\nRows with Season == 'Unknown': {unknown_count}\")\n",
    "\n",
    "if unknown_count > 0:\n",
    "    print(\"\\nSample Unknown rows (first 10):\")\n",
    "    print(df[df[\"Season\"] == \"Unknown\"].head(10)[[state_col, month_col, \"Season\"]])\n",
    "\n",
    "# ---------------------\n",
    "# Write back (overwrite) the same merged CSV\n",
    "# ---------------------\n",
    "df.to_csv(out_file, index=False)\n",
    "print(f\"\\nâœ” Updated CSV overwritten at: {out_file} (Season column added/updated)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73288b93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
